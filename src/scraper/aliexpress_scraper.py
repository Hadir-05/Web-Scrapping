"""
Module de scraping AliExpress avec recherche par image am√©lior√©e
"""
import asyncio
import os
import base64
from datetime import datetime
from typing import List, Optional, Tuple
from urllib.parse import urljoin, quote, urlparse
from pathlib import Path
import json

from crawlee.crawlers import PlaywrightCrawler, PlaywrightCrawlingContext
from playwright.async_api import Page, TimeoutError as PlaywrightTimeoutError

from src.models.data_models import ImageMetadata, ProductData


class AliExpressImageSearchScraper:
    """Scraper AliExpress pour la recherche par image am√©lior√©e"""

    def __init__(self, output_dir: str = "output"):
        self.output_dir = Path(output_dir)
        self.images_dir = self.output_dir / "images"
        self.images_dir.mkdir(parents=True, exist_ok=True)

        self.image_metadata_list: List[ImageMetadata] = []
        self.product_data_list: List[ProductData] = []
        self.image_counter = 0
        self.search_completed = False

    async def search_by_image(
        self,
        image_path: str,
        max_results: int = 20,
        headless: bool = True
    ) -> Tuple[List[ImageMetadata], List[ProductData]]:
        """
        Rechercher des produits sur AliExpress par image

        Args:
            image_path: Chemin vers l'image √† rechercher
            max_results: Nombre maximum de r√©sultats
            headless: Mode headless pour le navigateur

        Returns:
            Tuple contenant les listes de ImageMetadata et ProductData
        """
        self.image_metadata_list = []
        self.product_data_list = []
        self.image_counter = 0
        self.search_completed = False

        crawler = PlaywrightCrawler(
            max_requests_per_crawl=1,
            headless=headless,
            browser_type='chromium',
        )

        @crawler.router.default_handler
        async def request_handler(context: PlaywrightCrawlingContext) -> None:
            page = context.page

            # Effectuer la recherche par image et extraire les r√©sultats
            await self._perform_image_search_and_extract(context, image_path, max_results)

        # D√©marrer avec la page principale d'AliExpress
        await crawler.run(['https://www.aliexpress.com/'])

        return self.image_metadata_list, self.product_data_list

    async def _perform_image_search_and_extract(
        self,
        context: PlaywrightCrawlingContext,
        image_path: str,
        max_results: int
    ):
        """
        Effectuer la recherche par image et extraire les r√©sultats
        """
        page = context.page

        try:
            context.log.info("üåê Navigation vers AliExpress...")

            # Attendre le chargement complet
            await page.wait_for_load_state('domcontentloaded', timeout=30000)
            await page.wait_for_timeout(3000)

            context.log.info("üîç Recherche du bouton de recherche par image...")

            # M√©thode 1 : Chercher l'ic√¥ne de cam√©ra dans la barre de recherche
            camera_selectors = [
                # S√©lecteurs communs pour l'ic√¥ne de cam√©ra
                'button[aria-label*="Search by image"]',
                'button[aria-label*="search by image"]',
                'span[data-spm-anchor-id*="search.camera"]',
                '.search-bar__pic',
                '.search-upload-image',
                'div[class*="ImageSearch"]',
                'button:has(svg[class*="camera"])',
                'button:has([class*="camera"])',
                'span:has([class*="camera"])',
                # Ic√¥ne directe
                'i.search-photo-icon',
                '.comet-icon-camerafilled',
                'span.search-bar__camera-icon',
            ]

            camera_element = None
            for selector in camera_selectors:
                try:
                    elements = await page.query_selector_all(selector)
                    for elem in elements:
                        # V√©rifier si l'√©l√©ment est visible
                        if await elem.is_visible():
                            camera_element = elem
                            context.log.info(f"‚úÖ Bouton trouv√© avec le s√©lecteur: {selector}")
                            break
                    if camera_element:
                        break
                except Exception as e:
                    continue

            if camera_element:
                try:
                    context.log.info("üì∏ Clic sur le bouton de recherche par image...")

                    # Scroll vers l'√©l√©ment et attendre
                    await camera_element.scroll_into_view_if_needed()
                    await page.wait_for_timeout(1000)

                    # Cliquer
                    await camera_element.click()
                    await page.wait_for_timeout(2000)

                    context.log.info("üì§ Recherche de l'input file...")

                    # Attendre l'input file (peut √™tre cach√©)
                    file_input = None
                    input_selectors = [
                        'input[type="file"]',
                        'input[accept*="image"]',
                        'input[name*="image"]',
                    ]

                    for selector in input_selectors:
                        try:
                            file_input = await page.wait_for_selector(selector, timeout=5000, state='attached')
                            if file_input:
                                context.log.info(f"‚úÖ Input file trouv√©: {selector}")
                                break
                        except:
                            continue

                    if file_input:
                        context.log.info(f"üìÇ Upload de l'image: {image_path}")
                        await file_input.set_input_files(image_path)

                        # Attendre que l'image soit upload√©e et la recherche lanc√©e
                        context.log.info("‚è≥ Attente de la fin de l'upload et du chargement des r√©sultats...")
                        await page.wait_for_timeout(5000)

                        # Attendre la navigation ou les r√©sultats
                        try:
                            await page.wait_for_load_state('networkidle', timeout=30000)
                        except:
                            await page.wait_for_timeout(5000)

                        # Extraire les produits
                        context.log.info("üì¶ Extraction des produits depuis les r√©sultats...")
                        await self._extract_products_from_results(context, max_results)

                        self.search_completed = True
                        return

                    else:
                        context.log.warning("‚ùå Input file non trouv√© apr√®s le clic")

                except Exception as e:
                    context.log.error(f"‚ùå Erreur lors de l'upload: {e}")

            # Si on arrive ici, la m√©thode principale a √©chou√©
            if not self.search_completed:
                context.log.warning("‚ö†Ô∏è M√©thode standard √©chou√©e, tentative avec URL directe...")
                await self._try_direct_image_search_url(page, image_path, context, max_results)

        except Exception as e:
            context.log.error(f"‚ùå Erreur globale: {e}")
            # Derni√®re tentative
            await self._try_direct_image_search_url(page, image_path, context, max_results)

    async def _try_direct_image_search_url(
        self,
        page: Page,
        image_path: str,
        context: PlaywrightCrawlingContext,
        max_results: int
    ):
        """
        Tenter d'utiliser l'URL directe de recherche par image
        """
        try:
            context.log.info("üîó Tentative d'acc√®s direct √† la page de recherche par image...")

            # AliExpress a une page d√©di√©e pour la recherche par image
            # Essayer d'y acc√©der directement
            search_by_image_urls = [
                'https://www.aliexpress.com/wholesale',
                'https://www.aliexpress.us/wholesale',
            ]

            for url in search_by_image_urls:
                try:
                    await page.goto(url, wait_until='domcontentloaded', timeout=15000)
                    await page.wait_for_timeout(3000)

                    # Chercher √† nouveau le bouton de recherche par image sur cette page
                    camera_elem = await page.query_selector('button[aria-label*="image"], span.search-bar__camera-icon, i.search-photo-icon')

                    if camera_elem and await camera_elem.is_visible():
                        await camera_elem.click()
                        await page.wait_for_timeout(2000)

                        file_input = await page.wait_for_selector('input[type="file"]', timeout=5000)
                        if file_input:
                            await file_input.set_input_files(image_path)
                            await page.wait_for_timeout(5000)
                            await page.wait_for_load_state('networkidle', timeout=30000)

                            await self._extract_products_from_results(context, max_results)
                            self.search_completed = True
                            return

                except Exception as e:
                    context.log.warning(f"Tentative avec {url} √©chou√©e: {e}")
                    continue

            # Si tout a √©chou√©, informer l'utilisateur
            if not self.search_completed:
                context.log.error("‚ùå Impossible d'effectuer la recherche par image. AliExpress a peut-√™tre chang√© son interface.")

        except Exception as e:
            context.log.error(f"‚ùå Erreur lors de la tentative directe: {e}")

    async def _extract_products_from_results(self, context: PlaywrightCrawlingContext, max_results: int):
        """
        Extraire les produits depuis la page de r√©sultats de recherche par image
        """
        page = context.page
        url = page.url

        try:
            context.log.info(f"üìÑ Extraction depuis: {url}")

            # Attendre que les produits soient charg√©s
            await page.wait_for_timeout(3000)

            # S√©lecteurs pour les cartes de produits AliExpress
            product_selectors = [
                # S√©lecteurs de liste de produits
                'div[class*="search-card-item"]',
                'div[class*="product-card"]',
                'a[class*="search-card-item"]',
                'div[class*="list-item"]',
                'div[data-product-id]',
                'article[class*="product"]',
                '.list--item--main',
                # Autres s√©lecteurs communs
                'div.manhattan--container--product',
            ]

            products = []
            for selector in product_selectors:
                try:
                    products = await page.query_selector_all(selector)
                    if len(products) > 0:
                        context.log.info(f"‚úÖ {len(products)} produits trouv√©s avec: {selector}")
                        break
                except:
                    continue

            if not products:
                context.log.warning("‚ö†Ô∏è Aucun produit trouv√© avec les s√©lecteurs standards")
                # Essayer de trouver tous les liens de produits
                products = await page.query_selector_all('a[href*="/item/"]')
                if products:
                    context.log.info(f"‚úÖ {len(products)} liens de produits trouv√©s")

            # Limiter au nombre souhait√©
            products = products[:max_results]
            context.log.info(f"üìä Traitement de {len(products)} produits...")

            for idx, product in enumerate(products):
                try:
                    # Extraire l'URL du produit
                    product_url = ""
                    try:
                        product_url = await product.get_attribute('href')
                        if product_url and not product_url.startswith('http'):
                            product_url = urljoin(url, product_url)
                    except:
                        pass

                    if not product_url:
                        link_elem = await product.query_selector('a[href*="/item/"]')
                        if link_elem:
                            product_url = await link_elem.get_attribute('href')
                            if product_url and not product_url.startswith('http'):
                                product_url = urljoin(url, product_url)

                    # Extraire le titre
                    title = f"Product {idx + 1}"
                    title_selectors = [
                        'h1', 'h2', 'h3',
                        '[class*="title"]',
                        '[class*="name"]',
                        '[class*="product-title"]',
                    ]

                    for selector in title_selectors:
                        try:
                            title_elem = await product.query_selector(selector)
                            if title_elem:
                                title_text = await title_elem.inner_text()
                                if title_text and len(title_text.strip()) > 0:
                                    title = title_text.strip()
                                    break
                        except:
                            continue

                    # Extraire le prix
                    price = "N/A"
                    price_selectors = [
                        '[class*="price"]',
                        '[class*="amount"]',
                        'span:has-text("$")',
                        'span:has-text("‚Ç¨")',
                    ]

                    for selector in price_selectors:
                        try:
                            price_elem = await product.query_selector(selector)
                            if price_elem:
                                price_text = await price_elem.inner_text()
                                if price_text:
                                    price = price_text.strip()
                                    break
                        except:
                            continue

                    # Extraire l'image principale
                    src_image = ""
                    img_elem = await product.query_selector('img')
                    if img_elem:
                        src = await img_elem.get_attribute('src')
                        if not src:
                            src = await img_elem.get_attribute('data-src')
                        if not src:
                            src = await img_elem.get_attribute('data-lazy-src')
                        if src:
                            if not src.startswith('http'):
                                src_image = urljoin(url, src)
                            else:
                                src_image = src

                    # T√©l√©charger l'image
                    product_image_paths = []
                    if src_image:
                        img_path = await self._download_image(page, src_image)
                        if img_path:
                            product_image_paths.append(img_path)

                            # Ajouter aux m√©tadonn√©es d'images
                            img_metadata = ImageMetadata(
                                src=src_image,
                                link=product_url or url
                            )
                            self.image_metadata_list.append(img_metadata)

                    # Prendre une capture d'√©cran du produit
                    screenshot_filename = f"screenshot_product_{len(self.product_data_list) + 1}.png"
                    screenshot_path = self.images_dir / screenshot_filename

                    try:
                        await product.screenshot(path=str(screenshot_path), timeout=5000)
                    except:
                        screenshot_path = Path("")

                    # Cr√©er ProductData
                    product_data = ProductData(
                        item_url=product_url or url,
                        collection_date=datetime.now(),
                        src_image=src_image,
                        title=title,
                        description="",
                        price=price,
                        screenshot_path=str(screenshot_path),
                        product_image_paths=product_image_paths
                    )
                    self.product_data_list.append(product_data)

                    context.log.info(f"‚úÖ Produit {idx + 1}/{len(products)}: {title[:50]}")

                except Exception as e:
                    context.log.error(f"‚ùå Erreur produit {idx}: {e}")
                    continue

            context.log.info(f"üéâ Extraction termin√©e: {len(self.product_data_list)} produits extraits")

        except Exception as e:
            context.log.error(f"‚ùå Erreur lors de l'extraction des produits: {e}")

    async def _download_image(self, page: Page, image_url: str) -> str:
        """T√©l√©charger une image et retourner le chemin local"""
        try:
            # Cr√©er un nom de fichier unique
            self.image_counter += 1
            ext = '.jpg'
            if '.' in image_url:
                parsed = urlparse(image_url)
                ext = os.path.splitext(parsed.path)[1] or '.jpg'
            filename = f"image_{self.image_counter:04d}{ext}"
            filepath = self.images_dir / filename

            # T√©l√©charger l'image
            try:
                response = await page.request.get(image_url, timeout=10000)
                if response.status == 200:
                    with open(filepath, 'wb') as f:
                        f.write(await response.body())
                    return str(filepath)
            except Exception as e:
                print(f"Erreur t√©l√©chargement {image_url}: {e}")

        except Exception as e:
            print(f"Erreur lors du t√©l√©chargement de {image_url}: {e}")

        return ""


async def search_aliexpress_by_image(
    image_path: str,
    output_dir: str = "output",
    max_results: int = 20
) -> Tuple[List[ImageMetadata], List[ProductData]]:
    """
    Fonction utilitaire pour rechercher sur AliExpress par image

    Args:
        image_path: Chemin vers l'image √† rechercher
        output_dir: R√©pertoire de sortie
        max_results: Nombre maximum de r√©sultats

    Returns:
        Tuple contenant les listes de ImageMetadata et ProductData
    """
    scraper = AliExpressImageSearchScraper(output_dir)
    return await scraper.search_by_image(image_path, max_results)

"""
Module de recherche par similarit√© d'images
Utilise CLIP pour des embeddings de haute qualit√©
"""
import os
from typing import List, Tuple, Optional
from pathlib import Path
import io

from PIL import Image
import numpy as np

# Essayer d'importer CLIP, sinon utiliser le fallback perceptual hashing
try:
    from src.image_search.clip_similarity import CLIPSimilarityModel
    CLIP_AVAILABLE = True
except ImportError:
    CLIP_AVAILABLE = False
    print("‚ö†Ô∏è CLIP not available, falling back to perceptual hashing")
    import imagehash


class ImageSimilaritySearch:
    """
    Classe pour la recherche de similarit√© d'images
    Utilise CLIP si disponible, sinon perceptual hashing
    """

    def __init__(self, use_clip: bool = True):
        """
        Initialise la recherche de similarit√©

        Args:
            use_clip: Utiliser CLIP si disponible (True par d√©faut)
        """
        self.use_clip = use_clip and CLIP_AVAILABLE

        if self.use_clip:
            print("üéØ Utilisation de CLIP pour la similarit√© d'images")
            self.clip_model = None  # Sera initialis√© lors de la premi√®re recherche
            self.image_embeddings = {}  # {image_path: embedding}
        else:
            print("üîç Utilisation du perceptual hashing pour la similarit√©")
            self.image_hashes = {}  # {image_path: hash}

        self.image_info = {}    # {image_path: metadata}

    def add_image(self, image_path: str, metadata: dict = None):
        """
        Ajouter une image √† l'index de recherche

        Args:
            image_path: Chemin vers l'image
            metadata: M√©tadonn√©es optionnelles associ√©es √† l'image
        """
        try:
            if self.use_clip:
                # Initialiser CLIP si n√©cessaire
                if self.clip_model is None:
                    self.clip_model = CLIPSimilarityModel()

                # Calculer l'embedding CLIP
                embedding = self.clip_model.compute_features(image_path)
                self.image_embeddings[image_path] = embedding
            else:
                # Perceptual hashing (fallback)
                img = Image.open(image_path)
                ahash = imagehash.average_hash(img)
                phash = imagehash.phash(img)
                dhash = imagehash.dhash(img)
                whash = imagehash.whash(img)

                self.image_hashes[image_path] = {
                    'ahash': ahash,
                    'phash': phash,
                    'dhash': dhash,
                    'whash': whash
                }

            # Stocker les m√©tadonn√©es
            self.image_info[image_path] = metadata or {}

        except Exception as e:
            print(f"Erreur lors de l'ajout de l'image {image_path}: {e}")

    def add_images_from_directory(self, directory: str, metadata_func=None):
        """
        Ajouter toutes les images d'un r√©pertoire √† l'index

        Args:
            directory: R√©pertoire contenant les images
            metadata_func: Fonction optionnelle pour g√©n√©rer les m√©tadonn√©es (prend le chemin en argument)
        """
        image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'}
        directory_path = Path(directory)

        for image_path in directory_path.glob('*'):
            if image_path.suffix.lower() in image_extensions:
                metadata = metadata_func(str(image_path)) if metadata_func else None
                self.add_image(str(image_path), metadata)

    def search_similar(
        self,
        query_image_path: str,
        top_k: int = 5,
        threshold: float = 0.5
    ) -> List[Tuple[str, float, dict]]:
        """
        Rechercher les images similaires √† l'image de requ√™te

        Args:
            query_image_path: Chemin vers l'image de requ√™te
            top_k: Nombre de r√©sultats √† retourner
            threshold: Seuil de similarit√© minimale (0-1, plus haut = plus similaire)
                      - Pour CLIP: 0.5 par d√©faut (similarit√© cosinus)
                      - Pour hashing: 10 par d√©faut (distance hamming)

        Returns:
            Liste de tuples (chemin_image, score_similarit√©, m√©tadonn√©es)
        """
        try:
            if self.use_clip:
                # Initialiser CLIP si n√©cessaire
                if self.clip_model is None:
                    self.clip_model = CLIPSimilarityModel()

                # Calculer l'embedding de la requ√™te
                query_embedding = self.clip_model.compute_features(query_image_path)

                # Calculer la similarit√© cosinus avec toutes les images
                from sklearn.metrics.pairwise import cosine_similarity

                similarities = []
                for image_path, embedding in self.image_embeddings.items():
                    sim = cosine_similarity(query_embedding, embedding)[0][0]
                    similarity_score = float(sim)

                    if similarity_score >= threshold:
                        similarities.append((
                            image_path,
                            similarity_score,
                            self.image_info.get(image_path, {})
                        ))

            else:
                # Perceptual hashing (fallback)
                query_img = Image.open(query_image_path)

                query_ahash = imagehash.average_hash(query_img)
                query_phash = imagehash.phash(query_img)
                query_dhash = imagehash.dhash(query_img)
                query_whash = imagehash.whash(query_img)

                similarities = []
                hash_threshold = int(threshold) if threshold < 100 else 10

                for image_path, hashes in self.image_hashes.items():
                    ahash_dist = query_ahash - hashes['ahash']
                    phash_dist = query_phash - hashes['phash']
                    dhash_dist = query_dhash - hashes['dhash']
                    whash_dist = query_whash - hashes['whash']

                    avg_distance = (ahash_dist + 2*phash_dist + dhash_dist + whash_dist) / 5.0
                    similarity_score = max(0, 1 - (avg_distance / 64.0))

                    if avg_distance <= hash_threshold:
                        similarities.append((
                            image_path,
                            similarity_score,
                            self.image_info.get(image_path, {})
                        ))

            # Trier par score de similarit√© d√©croissant
            similarities.sort(key=lambda x: x[1], reverse=True)

            return similarities[:top_k]

        except Exception as e:
            print(f"Erreur lors de la recherche de similarit√©: {e}")
            import traceback
            traceback.print_exc()
            return []

    def search_similar_from_bytes(
        self,
        image_bytes: bytes,
        top_k: int = 5,
        threshold: int = 10
    ) -> List[Tuple[str, float, dict]]:
        """
        Rechercher les images similaires √† partir de bytes d'image

        Args:
            image_bytes: Bytes de l'image de requ√™te
            top_k: Nombre de r√©sultats √† retourner
            threshold: Seuil de distance maximale

        Returns:
            Liste de tuples (chemin_image, score_similarit√©, m√©tadonn√©es)
        """
        try:
            query_img = Image.open(io.BytesIO(image_bytes))

            # Calculer les hashes de l'image de requ√™te
            query_ahash = imagehash.average_hash(query_img)
            query_phash = imagehash.phash(query_img)
            query_dhash = imagehash.dhash(query_img)
            query_whash = imagehash.whash(query_img)

            # Calculer les distances pour toutes les images
            similarities = []
            for image_path, hashes in self.image_hashes.items():
                # Calculer la distance moyenne de tous les hashes
                ahash_dist = query_ahash - hashes['ahash']
                phash_dist = query_phash - hashes['phash']
                dhash_dist = query_dhash - hashes['dhash']
                whash_dist = query_whash - hashes['whash']

                # Distance moyenne pond√©r√©e
                avg_distance = (ahash_dist + 2*phash_dist + dhash_dist + whash_dist) / 5.0

                # Convertir la distance en score de similarit√©
                similarity_score = max(0, 1 - (avg_distance / 64.0))

                if avg_distance <= threshold:
                    similarities.append((
                        image_path,
                        similarity_score,
                        self.image_info.get(image_path, {})
                    ))

            # Trier par score de similarit√© d√©croissant
            similarities.sort(key=lambda x: x[1], reverse=True)

            return similarities[:top_k]

        except Exception as e:
            print(f"Erreur lors de la recherche de similarit√©: {e}")
            return []

    def find_duplicates(self, threshold: int = 5) -> List[List[str]]:
        """
        Trouver les images en double dans l'index

        Args:
            threshold: Seuil de distance pour consid√©rer deux images comme duplicata

        Returns:
            Liste de groupes d'images similaires
        """
        duplicates = []
        processed = set()

        for image_path, hashes in self.image_hashes.items():
            if image_path in processed:
                continue

            group = [image_path]
            processed.add(image_path)

            # Comparer avec toutes les autres images
            for other_path, other_hashes in self.image_hashes.items():
                if other_path in processed:
                    continue

                # Calculer la distance moyenne
                ahash_dist = hashes['ahash'] - other_hashes['ahash']
                phash_dist = hashes['phash'] - other_hashes['phash']
                dhash_dist = hashes['dhash'] - other_hashes['dhash']
                whash_dist = hashes['whash'] - other_hashes['whash']

                avg_distance = (ahash_dist + 2*phash_dist + dhash_dist + whash_dist) / 5.0

                if avg_distance <= threshold:
                    group.append(other_path)
                    processed.add(other_path)

            if len(group) > 1:
                duplicates.append(group)

        return duplicates

    def clear(self):
        """Vider l'index de recherche"""
        if self.use_clip:
            self.image_embeddings.clear()
        else:
            self.image_hashes.clear()
        self.image_info.clear()

    def get_stats(self) -> dict:
        """Obtenir des statistiques sur l'index"""
        if self.use_clip:
            total_images = len(self.image_embeddings)
        else:
            total_images = len(self.image_hashes)

        return {
            'total_images': total_images,
            'total_metadata': len(self.image_info),
            'using_clip': self.use_clip
        }

"""
Chargeur de mod√®les PyTorch avec cache Redis
Les mod√®les restent en m√©moire pour performance optimale
"""
import torch
import pickle
import redis
from pathlib import Path
from typing import Optional, Any
import logging

logger = logging.getLogger(__name__)


class ModelCache:
    """
    Cache Redis pour mod√®les PyTorch
    Garde les mod√®les en m√©moire pour √©viter rechargement
    """

    def __init__(
        self,
        redis_host: str = "localhost",
        redis_port: int = 6379,
        redis_password: str = "",
        redis_db: int = 0
    ):
        """
        Initialise la connexion Redis

        Args:
            redis_host: H√¥te Redis
            redis_port: Port Redis
            redis_password: Mot de passe Redis (optionnel)
            redis_db: Database Redis
        """
        try:
            self.redis_client = redis.Redis(
                host=redis_host,
                port=redis_port,
                password=redis_password if redis_password else None,
                db=redis_db,
                decode_responses=False  # Pour stocker des bytes
            )
            self.redis_client.ping()
            logger.info(f"‚úÖ Connect√© √† Redis: {redis_host}:{redis_port}")
        except redis.ConnectionError as e:
            logger.warning(f"‚ö†Ô∏è Redis non disponible: {str(e)}")
            logger.warning("Les mod√®les seront charg√©s en m√©moire locale")
            self.redis_client = None

        # Cache local en m√©moire (fallback si Redis indisponible)
        self.local_cache = {}

    def get_model(self, key: str) -> Optional[Any]:
        """
        R√©cup√®re un mod√®le depuis le cache

        Args:
            key: Cl√© du mod√®le

        Returns:
            Mod√®le PyTorch ou None
        """
        # Essayer Redis d'abord
        if self.redis_client:
            try:
                data = self.redis_client.get(key)
                if data:
                    logger.info(f"‚úÖ Mod√®le '{key}' r√©cup√©r√© depuis Redis")
                    return pickle.loads(data)
            except Exception as e:
                logger.warning(f"Erreur Redis get: {str(e)}")

        # Fallback: cache local
        if key in self.local_cache:
            logger.info(f"‚úÖ Mod√®le '{key}' r√©cup√©r√© depuis cache local")
            return self.local_cache[key]

        return None

    def set_model(self, key: str, model: Any, ttl: int = 3600):
        """
        Stocke un mod√®le dans le cache

        Args:
            key: Cl√© du mod√®le
            model: Mod√®le PyTorch
            ttl: Dur√©e de vie en secondes
        """
        # Stocker dans cache local
        self.local_cache[key] = model

        # Essayer de stocker dans Redis
        if self.redis_client:
            try:
                serialized = pickle.dumps(model)
                self.redis_client.setex(key, ttl, serialized)
                logger.info(f"‚úÖ Mod√®le '{key}' mis en cache Redis (TTL: {ttl}s)")
            except Exception as e:
                logger.warning(f"Erreur Redis set: {str(e)}")
        else:
            logger.info(f"‚úÖ Mod√®le '{key}' mis en cache local")


class ModelLoader:
    """
    Gestionnaire de chargement des mod√®les PyTorch
    """

    def __init__(self, cache: ModelCache, device: str = "cpu"):
        """
        Args:
            cache: Instance ModelCache
            device: 'cpu' ou 'cuda'
        """
        self.cache = cache
        self.device = device

    def load_model(
        self,
        model_path: str,
        model_key: str,
        cache_ttl: int = 3600
    ) -> Any:
        """
        Charge un mod√®le PyTorch (avec cache)

        Args:
            model_path: Chemin vers le fichier .pth
            model_key: Cl√© unique pour le cache
            cache_ttl: Dur√©e de vie du cache

        Returns:
            Mod√®le PyTorch charg√© et en mode eval

        Raises:
            FileNotFoundError: Si le fichier n'existe pas
            RuntimeError: Si erreur de chargement
        """
        # V√©rifier le cache
        cached_model = self.cache.get_model(model_key)
        if cached_model is not None:
            return cached_model

        # Charger depuis le fichier
        logger.info(f"üîÑ Chargement du mod√®le depuis {model_path}...")

        if not Path(model_path).exists():
            raise FileNotFoundError(
                f"Mod√®le non trouv√©: {model_path}\n"
                f"Placez vos mod√®les .pth dans le dossier models/"
            )

        try:
            # Charger le mod√®le
            model = torch.load(model_path, map_location=self.device)

            # Si c'est un state_dict, adapter selon votre architecture
            # Exemple: model = YourModelClass(); model.load_state_dict(...)

            # Mode √©valuation
            if hasattr(model, 'eval'):
                model.eval()

            # Mettre en cache
            self.cache.set_model(model_key, model, ttl=cache_ttl)

            logger.info(f"‚úÖ Mod√®le '{model_key}' charg√© sur {self.device}")
            return model

        except Exception as e:
            raise RuntimeError(f"Erreur chargement mod√®le: {str(e)}")


# Instance globale (initialis√©e au d√©marrage de l'app)
_model_cache: Optional[ModelCache] = None
_model_loader: Optional[ModelLoader] = None


def initialize_model_system(
    redis_host: str,
    redis_port: int,
    redis_password: str,
    device: str
):
    """
    Initialise le syst√®me de mod√®les

    Args:
        redis_host: H√¥te Redis
        redis_port: Port Redis
        redis_password: Mot de passe Redis
        device: Device PyTorch
    """
    global _model_cache, _model_loader

    _model_cache = ModelCache(
        redis_host=redis_host,
        redis_port=redis_port,
        redis_password=redis_password
    )

    _model_loader = ModelLoader(cache=_model_cache, device=device)

    logger.info("‚úÖ Syst√®me de mod√®les initialis√©")


def get_model_loader() -> ModelLoader:
    """R√©cup√®re le loader de mod√®les"""
    if _model_loader is None:
        raise RuntimeError("ModelLoader non initialis√©. Appelez initialize_model_system()")
    return _model_loader

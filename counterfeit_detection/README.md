# üõ°Ô∏è Anti-Counterfeit Detection System

Syst√®me complet de d√©tection automatique de contrefa√ßons de produits de luxe sur les sites e-commerce.

---

## üéØ Vue d'Ensemble

Ce syst√®me permet de :
- **Scraper** automatiquement les sites e-commerce (AliExpress, DHgate, Wish, etc.)
- **D√©tecter** les contrefa√ßons en utilisant l'IA (similarit√© d'images + matching de mots-cl√©s)
- **Analyser** les prix suspects
- **Alerter** en temps r√©el sur les d√©tections
- **Visualiser** les donn√©es dans un dashboard interactif

---

## üìÅ Architecture

```
counterfeit_detection/
‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îú‚îÄ‚îÄ models.py                 # Sch√©ma BDD (SQLAlchemy)
‚îÇ   ‚îî‚îÄ‚îÄ counterfeit_detection.db  # Base de donn√©es SQLite
‚îÇ
‚îú‚îÄ‚îÄ scrapers/
‚îÇ   ‚îú‚îÄ‚îÄ base_scraper.py          # Classe de base
‚îÇ   ‚îú‚îÄ‚îÄ aliexpress_scraper.py    # Scraper AliExpress
‚îÇ   ‚îî‚îÄ‚îÄ dhgate_scraper.py        # Scraper DHgate
‚îÇ
‚îú‚îÄ‚îÄ detectors/
‚îÇ   ‚îî‚îÄ‚îÄ counterfeit_detector.py  # Moteur de d√©tection AI
‚îÇ
‚îú‚îÄ‚îÄ alerts/
‚îÇ   ‚îî‚îÄ‚îÄ alert_manager.py         # Syst√®me d'alertes
‚îÇ
‚îú‚îÄ‚îÄ dashboard.py                  # Dashboard Streamlit
‚îú‚îÄ‚îÄ requirements.txt              # D√©pendances
‚îî‚îÄ‚îÄ README.md                     # Ce fichier
```

---

## üöÄ Installation

### 1. Installer les D√©pendances

```bash
cd counterfeit_detection
pip install -r requirements.txt
```

### 2. Initialiser la Base de Donn√©es

La base de donn√©es est cr√©√©e automatiquement au premier lancement.

```python
from database.models import DatabaseManager

db = DatabaseManager()
```

### 3. (Optionnel) Ajouter vos Mod√®les PyTorch

Si vous avez des mod√®les .pth pour la similarit√© d'images :

```bash
# Copier vos mod√®les
cp your_image_model.pth ../models/image_similarity.pth
```

---

## üìä Utilisation du Dashboard

### Lancer le Dashboard

```bash
cd counterfeit_detection
streamlit run dashboard.py
```

Acc√®s : **http://localhost:8501**

### Fonctionnalit√©s du Dashboard

#### 1. **üìä Dashboard** (Page d'accueil)
- Vue d'ensemble des statistiques
- Graphiques de d√©tections par site
- Distribution des risques
- D√©tections r√©centes √† haut risque

#### 2. **üîç New Scan** (Nouveau Scan)
- S√©lectionner un site (AliExpress, DHgate, etc.)
- Entrer une requ√™te de recherche (ex: "Louis Vuitton bag")
- D√©finir le nombre de pages √† scraper
- Lancer le scan automatique

**Exemple de recherche :**
```
Site: AliExpress
Query: Gucci handbag
Max Pages: 3
```

Le syst√®me va :
1. Scraper AliExpress
2. Analyser chaque produit trouv√©
3. D√©tecter les marques de luxe
4. Calculer les scores de risque
5. Sauvegarder les contrefa√ßons potentielles

#### 3. **üìã Detections List** (Liste des D√©tections)
- Voir toutes les contrefa√ßons d√©tect√©es
- Filtrer par site, risque, statut
- Exporter les donn√©es
- Marquer comme confirm√©/faux positif

#### 4. **‚öôÔ∏è Configuration**
- G√©rer les marques √† surveiller
- Configurer les scrapers
- Param√©trer les alertes (email, webhook)

#### 5. **üìà Analytics** (Analyses)
- Timeline des d√©tections
- Marques les plus cibl√©es
- Distribution des prix
- Rapports personnalis√©s

---

## üîç Utilisation Programmatique

### Exemple : Scanner AliExpress

```python
from scrapers.aliexpress_scraper import AliExpressScraper
from detectors.counterfeit_detector import CounterfeitDetector
from database.models import DatabaseManager

# Initialiser
scraper = AliExpressScraper()
detector = CounterfeitDetector()
db = DatabaseManager()

# Scraper
products = scraper.search("Louis Vuitton bag", max_pages=3)
print(f"Found {len(products)} products")

# D√©tecter les contrefa√ßons
for product in products:
    result = detector.detect_counterfeit(product, authentic_products=[])

    if result['overall_risk_score'] > 0.7:
        print(f"‚ö†Ô∏è Counterfeit detected!")
        print(f"  Title: {product['title']}")
        print(f"  Risk: {result['overall_risk_score']:.1%}")
        print(f"  Brands: {result['detected_brands']}")

        # Sauvegarder
        db.add_counterfeit(
            detection_id=f"AliExpress_{hash(product['url'])}",
            source_site="AliExpress",
            source_url=product['url'],
            title=product['title'],
            price=product.get('price'),
            image_urls=product.get('image_urls', []),
            overall_risk_score=result['overall_risk_score'],
            detected_brands=result['detected_brands'],
            confidence_level=result['confidence_level']
        )
```

### Exemple : Recherche Multi-Sites

```python
from scrapers.aliexpress_scraper import AliExpressScraper
from scrapers.dhgate_scraper import DHgateScraper

query = "Rolex watch"

scrapers = {
    'AliExpress': AliExpressScraper(),
    'DHgate': DHgateScraper()
}

all_products = []

for site_name, scraper in scrapers.items():
    print(f"Scanning {site_name}...")
    products = scraper.search(query, max_pages=2)
    all_products.extend(products)

print(f"Total products found: {len(all_products)}")
```

---

## ü§ñ Syst√®me de D√©tection

### Crit√®res de D√©tection

Le syst√®me utilise **4 crit√®res principaux** :

#### 1. **D√©tection de Marques** (30%)
- D√©tecte les marques de luxe dans le titre/description
- G√®re les variantes et fautes d'orthographe
- Exemple : "LV", "L.V", "Louis V" ‚Üí "Louis Vuitton"

#### 2. **Similarit√© d'Images** (30%)
- Compare avec les images des produits authentiques
- Utilise le mod√®le PyTorch fourni
- Score de 0 (diff√©rent) √† 1 (identique)

#### 3. **Analyse de Prix** (25%)
- D√©tecte les prix anormalement bas
- Exemple : Sac LV √† $50 au lieu de $2000 ‚Üí Score √©lev√©

#### 4. **Mots Suspects** (15%)
- D√©tecte : "replica", "copy", "AAA", "1:1", "mirror", etc.

### Niveaux de Risque

| Score | Niveau | Action |
|-------|--------|--------|
| 0.85 - 1.0 | üî¥ CRITICAL | Alerte imm√©diate |
| 0.70 - 0.84 | üü† HIGH | Revue prioritaire |
| 0.50 - 0.69 | üü° MEDIUM | Revue standard |
| 0.0 - 0.49 | üü¢ LOW | Monitoring |

---

## üìß Syst√®me d'Alertes

### Configurer les Alertes Email

```python
from alerts.alert_manager import AlertManager

alert_mgr = AlertManager(
    email_enabled=True,
    email_recipients=['security@company.com'],
    smtp_server='smtp.gmail.com',
    smtp_port=587,
    smtp_username='alerts@company.com',
    smtp_password='your_password'
)

# Envoyer une alerte
alert_mgr.send_alert(
    counterfeit_data={
        'title': 'Fake Louis Vuitton Bag',
        'risk_score': 0.95,
        'url': 'https://...'
    },
    alert_level='CRITICAL'
)
```

### Webhooks

```python
alert_mgr = AlertManager(
    webhook_enabled=True,
    webhook_url='https://hooks.slack.com/services/YOUR/WEBHOOK/URL'
)
```

---

## üìÖ Planification Automatique

### Scans Automatiques Quotidiens

Cr√©er un script `scheduled_scan.py` :

```python
import schedule
import time
from scrapers.aliexpress_scraper import AliExpressScraper
from detectors.counterfeit_detector import CounterfeitDetector

def daily_scan():
    """Scan quotidien"""
    brands = ["Louis Vuitton", "Gucci", "Rolex", "Herm√®s"]

    scraper = AliExpressScraper()
    detector = CounterfeitDetector()

    for brand in brands:
        print(f"Scanning for {brand}...")
        products = scraper.search(brand, max_pages=5)

        # D√©tection...
        # (code de d√©tection)

    print("Daily scan complete!")

# Planifier tous les jours √† 2h du matin
schedule.every().day.at("02:00").do(daily_scan)

while True:
    schedule.run_pending()
    time.sleep(60)
```

Lancer en arri√®re-plan :

```bash
nohup python scheduled_scan.py &
```

---

## üîß Personnalisation

### Ajouter un Nouveau Scraper

Cr√©er `scrapers/wish_scraper.py` :

```python
from scrapers.base_scraper import BaseScraper

class WishScraper(BaseScraper):
    @property
    def base_url(self):
        return "https://www.wish.com"

    @property
    def site_name(self):
        return "Wish"

    def search(self, query, max_pages=5):
        # Impl√©menter la logique de scraping
        pass

    def get_product_details(self, product_url):
        # Impl√©menter la r√©cup√©ration de d√©tails
        pass
```

### Ajouter des Marques

```python
detector = CounterfeitDetector()

# Ajouter de nouvelles marques
detector.luxury_brands.extend([
    "Omega",
    "Tag Heuer",
    "Patek Philippe"
])

# Ajouter des variantes
detector.brand_variants["Patek Philippe"] = [
    "Patek",
    "PP",
    "Patek P"
]
```

---

## üìä Base de Donn√©es

### Structure des Tables

#### `authentic_products`
Produits authentiques de r√©f√©rence

#### `counterfeit_products`
Contrefa√ßons d√©tect√©es

#### `counterfeit_actions`
Actions prises (alertes, takedowns, etc.)

#### `scraping_jobs`
Historique des scans

#### `brand_keywords`
Mots-cl√©s de marques

### Requ√™tes Utiles

```python
from database.models import DatabaseManager

db = DatabaseManager()

# Statistiques
stats = db.get_statistics()
print(f"Total counterfeits: {stats['total_counterfeits']}")

# R√©cup√©rer les contrefa√ßons √† haut risque
high_risk = db.get_counterfeits(filters={'min_risk': 0.85}, limit=50)

# Par site
aliexpress_counterfeits = db.get_counterfeits(filters={'site': 'AliExpress'})
```

---

## üö® Limites et Consid√©rations

### L√©gales
- ‚ö†Ô∏è **Respectez les ToS** des sites scrap√©s
- ‚ö†Ô∏è **Rate limiting** : Ne pas surcharger les serveurs
- ‚ö†Ô∏è **RGPD** : Gestion des donn√©es personnelles

### Techniques
- Les s√©lecteurs CSS peuvent changer (sites dynamiques)
- Certains sites utilisent du JavaScript (consid√©rer Selenium)
- Captchas peuvent bloquer le scraping
- Proxies recommand√©s pour gros volumes

### Recommandations
1. **Utiliser des proxies** pour √©viter les bans IP
2. **Respecter les d√©lais** entre requ√™tes (1-3 secondes)
3. **Sauvegarder r√©guli√®rement** la base de donn√©es
4. **Monitorer les logs** pour d√©tecter les erreurs
5. **Mettre √† jour** les scrapers r√©guli√®rement

---

## üìà M√©triques de Performance

### KPIs √† Suivre
- **Taux de d√©tection** : % de contrefa√ßons d√©tect√©es vs total de produits
- **Pr√©cision** : % de vrais positifs
- **Faux positifs** : Produits l√©gitimes d√©tect√©s comme contrefa√ßons
- **Temps de scan** : Dur√©e moyenne par page
- **Couverture** : Nombre de sites/pages scann√©s

---

## üõ†Ô∏è Maintenance

### Logs

Les logs sont dans `logs/counterfeit_detection.log`

```bash
tail -f logs/counterfeit_detection.log
```

### Backup Base de Donn√©es

```bash
# Backup
cp database/counterfeit_detection.db backups/db_$(date +%Y%m%d).db

# Restauration
cp backups/db_20240101.db database/counterfeit_detection.db
```

---

## üìû Support

Pour toute question :
- Email : security@company.com
- Documentation : Voir `/docs`

---

## üìÑ License

Propri√©taire - Tous droits r√©serv√©s

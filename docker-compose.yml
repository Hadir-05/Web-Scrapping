version: '3.8'

services:
  aliexpress-scraper:
    # Nom du service
    container_name: aliexpress_scraper

    # Build depuis le Dockerfile local
    build:
      context: .
      dockerfile: Dockerfile

    # Nom de l'image
    image: aliexpress-scraper:latest

    # Redémarrage automatique
    restart: unless-stopped

    # Ports exposés (hôte:container)
    ports:
      - "8501:8501"

    # Variables d'environnement
    environment:
      - STREAMLIT_SERVER_PORT=8501
      - STREAMLIT_SERVER_ADDRESS=0.0.0.0
      - STREAMLIT_SERVER_HEADLESS=true
      - STREAMLIT_BROWSER_GATHER_USAGE_STATS=false

    # Volumes pour persister les données
    volumes:
      # Persister les résultats de recherche
      - ./output_recherche1:/app/output_recherche1
      - ./output_recherche2:/app/output_recherche2
      - ./output_recherche3:/app/output_recherche3
      - ./output_recherche4:/app/output_recherche4
      - ./output_recherche5:/app/output_recherche5
      # Vous pouvez ajouter plus de volumes si nécessaire

      # Optionnel: Monter un dossier pour les images uploadées
      # - ./uploads:/app/uploads

    # Limites de ressources (optionnel mais recommandé)
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '2.0'
          memory: 4G

    # Healthcheck
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

    # Réseau
    networks:
      - scraper-network

# Réseau isolé pour l'application
networks:
  scraper-network:
    driver: bridge

# Volumes nommés (optionnel, si vous préférez volumes Docker au lieu de bind mounts)
# volumes:
#   scraper-data:
#   scraper-cache:
